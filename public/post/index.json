[
    
        
            {
                "ref": "https://duncip.netlify.app/2020/06/08/exploring-tidymodels-with-regression/",
                "title": "Exploring Tidymodels with regression",
                "section": "post",
                "date" : "2020.06.08",
                "body": "\nMost of the things below are learnt through materials provided by Julia Silge (her course) and Alison Hill’s course at rstudio::conf(2020). It’s mainly to have a reference for myself in terms of what the Tidymodels workflow is as it makes modeling much easier. I’m not aiming for accuracy of models here (and the comparisons are not great when using RMSE considering different processes), instead, I just want to document the Tidymodels process so I can easily implement it in the future.\nExplore\rLet’s have a look at the data - I don’t want to do too much data manipulation here as want to focus on the aspect of a simple Tidymodels workflow!\names %\u0026gt;%\rhead(5)\r#\u0026gt; # A tibble: 5 x 81\r#\u0026gt; MS_SubClass MS_Zoning Lot_Frontage Lot_Area Street Alley Lot_Shape\r#\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; #\u0026gt; 1 One_Story_~ Resident~ 141 31770 Pave No_A~ Slightly~\r#\u0026gt; 2 One_Story_~ Resident~ 80 11622 Pave No_A~ Regular #\u0026gt; 3 One_Story_~ Resident~ 81 14267 Pave No_A~ Slightly~\r#\u0026gt; 4 One_Story_~ Resident~ 93 11160 Pave No_A~ Regular #\u0026gt; 5 Two_Story_~ Resident~ 74 13830 Pave No_A~ Slightly~\r#\u0026gt; # ... with 74 more variables: Land_Contour \u0026lt;fct\u0026gt;, Utilities \u0026lt;fct\u0026gt;,\r#\u0026gt; # Lot_Config \u0026lt;fct\u0026gt;, Land_Slope \u0026lt;fct\u0026gt;, Neighborhood \u0026lt;fct\u0026gt;, Condition_1 \u0026lt;fct\u0026gt;,\r#\u0026gt; # Condition_2 \u0026lt;fct\u0026gt;, Bldg_Type \u0026lt;fct\u0026gt;, House_Style \u0026lt;fct\u0026gt;, Overall_Qual \u0026lt;fct\u0026gt;,\r#\u0026gt; # Overall_Cond \u0026lt;fct\u0026gt;, Year_Built \u0026lt;int\u0026gt;, Year_Remod_Add \u0026lt;int\u0026gt;,\r#\u0026gt; # Roof_Style \u0026lt;fct\u0026gt;, Roof_Matl \u0026lt;fct\u0026gt;, Exterior_1st \u0026lt;fct\u0026gt;, Exterior_2nd \u0026lt;fct\u0026gt;,\r#\u0026gt; # Mas_Vnr_Type \u0026lt;fct\u0026gt;, Mas_Vnr_Area \u0026lt;dbl\u0026gt;, Exter_Qual \u0026lt;fct\u0026gt;, Exter_Cond \u0026lt;fct\u0026gt;,\r#\u0026gt; # Foundation \u0026lt;fct\u0026gt;, Bsmt_Qual \u0026lt;fct\u0026gt;, Bsmt_Cond \u0026lt;fct\u0026gt;, Bsmt_Exposure \u0026lt;fct\u0026gt;,\r#\u0026gt; # BsmtFin_Type_1 \u0026lt;fct\u0026gt;, BsmtFin_SF_1 \u0026lt;dbl\u0026gt;, BsmtFin_Type_2 \u0026lt;fct\u0026gt;,\r#\u0026gt; # BsmtFin_SF_2 \u0026lt;dbl\u0026gt;, Bsmt_Unf_SF \u0026lt;dbl\u0026gt;, Total_Bsmt_SF \u0026lt;dbl\u0026gt;, Heating \u0026lt;fct\u0026gt;,\r#\u0026gt; # Heating_QC \u0026lt;fct\u0026gt;, Central_Air \u0026lt;fct\u0026gt;, Electrical \u0026lt;fct\u0026gt;, First_Flr_SF \u0026lt;int\u0026gt;,\r#\u0026gt; # Second_Flr_SF \u0026lt;int\u0026gt;, Low_Qual_Fin_SF \u0026lt;int\u0026gt;, Gr_Liv_Area \u0026lt;int\u0026gt;,\r#\u0026gt; # Bsmt_Full_Bath \u0026lt;dbl\u0026gt;, Bsmt_Half_Bath \u0026lt;dbl\u0026gt;, Full_Bath \u0026lt;int\u0026gt;,\r#\u0026gt; # Half_Bath \u0026lt;int\u0026gt;, Bedroom_AbvGr \u0026lt;int\u0026gt;, Kitchen_AbvGr \u0026lt;int\u0026gt;,\r#\u0026gt; # Kitchen_Qual \u0026lt;fct\u0026gt;, TotRms_AbvGrd \u0026lt;int\u0026gt;, Functional \u0026lt;fct\u0026gt;,\r#\u0026gt; # Fireplaces \u0026lt;int\u0026gt;, Fireplace_Qu \u0026lt;fct\u0026gt;, Garage_Type \u0026lt;fct\u0026gt;,\r#\u0026gt; # Garage_Finish \u0026lt;fct\u0026gt;, Garage_Cars \u0026lt;dbl\u0026gt;, Garage_Area \u0026lt;dbl\u0026gt;,\r#\u0026gt; # Garage_Qual \u0026lt;fct\u0026gt;, Garage_Cond \u0026lt;fct\u0026gt;, Paved_Drive \u0026lt;fct\u0026gt;,\r#\u0026gt; # Wood_Deck_SF \u0026lt;int\u0026gt;, Open_Porch_SF \u0026lt;int\u0026gt;, Enclosed_Porch \u0026lt;int\u0026gt;,\r#\u0026gt; # Three_season_porch \u0026lt;int\u0026gt;, Screen_Porch \u0026lt;int\u0026gt;, Pool_Area \u0026lt;int\u0026gt;,\r#\u0026gt; # Pool_QC \u0026lt;fct\u0026gt;, Fence \u0026lt;fct\u0026gt;, Misc_Feature \u0026lt;fct\u0026gt;, Misc_Val \u0026lt;int\u0026gt;,\r#\u0026gt; # Mo_Sold \u0026lt;int\u0026gt;, Year_Sold \u0026lt;int\u0026gt;, Sale_Type \u0026lt;fct\u0026gt;, Sale_Condition \u0026lt;fct\u0026gt;,\r#\u0026gt; # Sale_Price \u0026lt;int\u0026gt;, Longitude \u0026lt;dbl\u0026gt;, Latitude \u0026lt;dbl\u0026gt;\rImmediately the amount of columns jumps out. I will start with cleaning the names and, because I think there’s going to be quite a lot of overlap between some of the variables, I’m going to select some that I think will be useful in predicting house price. Just glimpsing over the data, let’s keep longitude, latitude, lot_area, neighborhood (though may overlap with long / lat), year_sold and overall_qual.\names_e \u0026lt;- ames %\u0026gt;%\rjanitor::clean_names() %\u0026gt;%\rselect(longitude, latitude, lot_area,\rneighborhood, year_sold, overall_qual, sale_price)\rglimpse(ames_e)\r#\u0026gt; Rows: 2,930\r#\u0026gt; Columns: 7\r#\u0026gt; $ longitude \u0026lt;dbl\u0026gt; -93.61975, -93.61976, -93.61939, -93.61732, -93.63893,...\r#\u0026gt; $ latitude \u0026lt;dbl\u0026gt; 42.05403, 42.05301, 42.05266, 42.05125, 42.06090, 42.0...\r#\u0026gt; $ lot_area \u0026lt;int\u0026gt; 31770, 11622, 14267, 11160, 13830, 9978, 4920, 5005, 5...\r#\u0026gt; $ neighborhood \u0026lt;fct\u0026gt; North_Ames, North_Ames, North_Ames, North_Ames, Gilber...\r#\u0026gt; $ year_sold \u0026lt;int\u0026gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, ...\r#\u0026gt; $ overall_qual \u0026lt;fct\u0026gt; Above_Average, Average, Above_Average, Good, Average, ...\r#\u0026gt; $ sale_price \u0026lt;int\u0026gt; 215000, 105000, 172000, 244000, 189900, 195500, 213500...\rLet’s plot distribution of sale_price to see if it there’s anything weird going on:\nggplot(ames_e, aes(sale_price)) +\rgeom_histogram(bins = 30, alpha = .6, fill = \u0026quot;midnightblue\u0026quot;) +\rscale_x_continuous(labels = scales::dollar_format()) +\rtheme_ipsum_rc() +\rlabs(y = NULL,\rx = \u0026quot;Cost\u0026quot;,\rtitle = \u0026quot;Distribution of house prices in Ames\u0026quot;)\rWe can see there are a few extreme cases where house prices are \u0026gt; $400k. Additionally, because of the high numbers, it might be good to log10 but I will try without first. It is interesting to me though that these are mainly in one neighbourhood (Northridge Heights) but when looking at the distribution of that specific neighbourhood, it is still similar to that of the overall dataset!\nAnyway, there is not much else to explore here. Instead, let’s look at the Tidymodel process.\n\rModel 1\rI’m only going to be using regression models for this article and the aim is to see if we can predict house prices based on the predictors we picked. I’ll start by splitting the data and also create some folds so we don’t have to touch the testing data until later.\nSplitting\rames_split \u0026lt;- initial_split(ames_e)\rames_train \u0026lt;- training(ames_split)\rames_test \u0026lt;- testing(ames_split)\rset.seed(123)\rames_folds \u0026lt;- vfold_cv(ames_train)\rNeed to remember that the general approach to Tidymodels is:\nRecipe\n\rModel\n\rWorkflow\n\rFit\n\rRepeat\n\r\rIn terms of recipe, I don’t think there is much to do here currently. We may have to specify a recipe to log our sale_price variable but let’s try it without first. Usually though, a recipe can allow us to define many steps that make things like normalising / centering data easier. Can also help with zero variables.\nrf_recipe \u0026lt;-\rrecipe(sale_price ~ .,\rdata = ames_train)\rNow we can have a look at the model. We’ll start with the random forest which has 3 hyper-parameters we can tune: mtry, trees, and min_n. For the engine, we’ll use ranger which is a “fast implementation of random forests or recursive partitioning particularly suited for high dimensional data”. It supports both classification and regression so we have to specify that we’re doing regression!\nrf_model \u0026lt;-\rrand_forest() %\u0026gt;%\rset_engine(\u0026quot;ranger\u0026quot;) %\u0026gt;%\rset_mode(\u0026quot;regression\u0026quot;)\rrf_model %\u0026gt;% translate()\r#\u0026gt; Random Forest Model Specification (regression)\r#\u0026gt; #\u0026gt; Computational engine: ranger #\u0026gt; #\u0026gt; Model fit template:\r#\u0026gt; ranger::ranger(formula = missing_arg(), data = missing_arg(), #\u0026gt; case.weights = missing_arg(), num.threads = 1, verbose = FALSE, #\u0026gt; seed = sample.int(10^5, 1))\rNow it’s time for the workflow. Workflow in Tidymodels helps us create an object that binds together the pre-processing, modeling, AND post-processing requests. This makes it much easier to oversee what exactly is going to happen in a model (when combined with a recipe) and additionally, we can use commands like update_workflow() for different models.\nrf_wf \u0026lt;-\rworkflow() %\u0026gt;%\radd_recipe(rf_recipe) %\u0026gt;%\radd_model(rf_model)\rsummary(rf_wf)\r#\u0026gt; Length Class Mode #\u0026gt; pre 2 stage_pre list #\u0026gt; fit 2 stage_fit list #\u0026gt; post 1 stage_post list #\u0026gt; trained 1 -none- logical\rLastly we fit and see what the metrics look like for the folds. This way we can see if we want to attempt trying it on the testing model or if we further want to adjust our hyper-parameters (maybe with a grid).\nset.seed(123)\rrf_fit \u0026lt;-\rrf_wf %\u0026gt;%\rfit_resamples(resamples = ames_folds)\rrf_fit %\u0026gt;%\rcollect_metrics()\r#\u0026gt; # A tibble: 2 x 5\r#\u0026gt; .metric .estimator mean n std_err\r#\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt;\r#\u0026gt; 1 rmse standard 32202. 10 780. #\u0026gt; 2 rsq standard 0.839 10 0.0110\rThe R2 looks okay for the training set - sitting at 0.83 and we have an RMSE of $32k. Let’s see what it looks like on the testing data! I think we should have log10’d the sale_price but let’s go ahead and test it on the testing data and then for model 2 I will use log10.\n\rPredict\rset.seed(123)\rrf_last_fit \u0026lt;-\rrf_wf %\u0026gt;%\rlast_fit(split = ames_split)\rresults \u0026lt;- rf_last_fit %\u0026gt;% collect_metrics()\rrf_last_fit %\u0026gt;%\rcollect_predictions() %\u0026gt;%\rggplot(aes(.pred, sale_price)) +\rgeom_abline(col = \u0026quot;green\u0026quot;, lty = 2) +\rgeom_point(alpha = .4, colour = \u0026quot;midnightblue\u0026quot;) +\rannotate(\u0026quot;text\u0026quot;, x = Inf, y = Inf, hjust = 1.5, vjust = 2, label = paste(\u0026quot;RMSE: \u0026quot;, round(results$.estimate[1], 4))) +\rlabs(title = \u0026quot;Random tree model\u0026quot;,\rsubtitle = \u0026quot;No hyperparameters tuned, ranger engine\u0026quot;) +\rscale_x_continuous(labels = scales::dollar_format()) +\rscale_y_continuous(labels = scales::dollar_format())\rThe RMSE for the test set is $33k which means that on average, the predictions are about 33k off the actuals. The R2 looks about similar to the training set though, and there’s not SUCH a big difference between training and testing RMSE as to cause alarm. Now let’s try something similar but with log10. I attempted to do the hyper-parameter tuning but the amount of time it takes (in terms of computing), I’d rather leave it to a future post. Let’s log10 the sale_price column to see if that makes a difference.\n\r\rModel 2\rWe have already defined the model above and for now, won’t edit any of the args so let’s try and simply update our recipe and add that to our workflow. Let’s have another look at how our recipe, rf_recipe is defined:\nrf_model\r#\u0026gt; Random Forest Model Specification (regression)\r#\u0026gt; #\u0026gt; Computational engine: ranger\rrf_recipe\r#\u0026gt; Data Recipe\r#\u0026gt; #\u0026gt; Inputs:\r#\u0026gt; #\u0026gt; role #variables\r#\u0026gt; outcome 1\r#\u0026gt; predictor 6\rAll I did initially was put in the formula (which I could’ve done with add_formula in workflow as there weren’t any recipe stats) so I just need to add a step. Luckily, the recipe package has very straightforward function names so it should be clear.\nrf_log10_recipe \u0026lt;-\rrecipe(sale_price ~ .,\rdata = ames_train) %\u0026gt;%\rstep_log(sale_price, base = 10)\rAnd now when I run rf_log10_recipe it should say what operation it’s going to run once I’ve added it to the workflow and fitted it.\nrf_log10_recipe\r#\u0026gt; Data Recipe\r#\u0026gt; #\u0026gt; Inputs:\r#\u0026gt; #\u0026gt; role #variables\r#\u0026gt; outcome 1\r#\u0026gt; predictor 6\r#\u0026gt; #\u0026gt; Operations:\r#\u0026gt; #\u0026gt; Log transformation on sale_price\rIn the course linked in the introduction, Julia demonstrates how easy it is to update existing workflows with update_model() and update_recipe(). In this case, I’m just updating the recipe so let’s see how it works.\nrf_log10_wf \u0026lt;- rf_wf %\u0026gt;%\rupdate_recipe(rf_log10_recipe)\rNow rather than having to go back and also add model to the workflow (and whatever else if we had a more complicated workflow), we simply call the updated recipe and then we are ready to fit another model. This makes it a lot easier to tune models repeatedly and to test them for accuracy.\nset.seed(123)\rrf_log10_fit \u0026lt;-\rrf_log10_wf %\u0026gt;%\rfit_resamples(resamples = ames_folds)\rrf_log10_fit %\u0026gt;%\rcollect_metrics()\r#\u0026gt; # A tibble: 2 x 5\r#\u0026gt; .metric .estimator mean n std_err\r#\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt;\r#\u0026gt; 1 rmse standard 0.0781 10 0.00338\r#\u0026gt; 2 rsq standard 0.810 10 0.0134\rThe R2 has actually gone down a bit but well, the focus is on the routine, not the outcome (here)! Let’s fit on the test set and see how it looks.\nset.seed(123)\rrf_log10_last_fit \u0026lt;-\rrf_log10_wf %\u0026gt;%\rlast_fit(split = ames_split)\rresults_log10 \u0026lt;- rf_log10_last_fit %\u0026gt;% collect_metrics()\rrf_log10_last_fit %\u0026gt;%\rcollect_predictions() %\u0026gt;%\rggplot(aes(.pred, sale_price)) +\rgeom_abline(col = \u0026quot;green\u0026quot;, lty = 2) +\rgeom_point(alpha = .4, colour = \u0026quot;midnightblue\u0026quot;) +\rannotate(\u0026quot;text\u0026quot;, x = Inf, y = Inf, hjust = 6.5, vjust = 2.5, label = paste(\u0026quot;RMSE: \u0026quot;, round(results_log10$.estimate[1], 4))) +\rlabs(title = \u0026quot;Random tree model\u0026quot;,\rsubtitle = \u0026quot;No hyperparameters tuned, ranger engine, log10 sale_price\u0026quot;) +\rscale_x_continuous(labels = scales::dollar_format()) +\rscale_y_continuous(labels = scales::dollar_format())\rUnfortunately because we changed the parameters it’s difficult to compare the two models. We could log10 the RMSE of the first model and see that it’s 4.51 but that’s not a good way. We could compare the R2 in which case the confidence in model 2 goes down as it’s lower. Anyway, lastly I want to implement a linear model that is described on the Tidymodels blog. This one will also use log10 so we CAN compare the RMSE.\n\rModel 3\rI want to use glmnet which relies on regularization so will need to center and scale the predictors first. I’m updating the recipe AND the model this time so I’m not going to use update_recipe() or update_model(), I’ll just create new ones altogether.\nglm_rec \u0026lt;- recipe(sale_price ~.,\rdata = ames_train) %\u0026gt;%\rstep_other(neighborhood) %\u0026gt;%\rstep_dummy(all_nominal()) %\u0026gt;%\rstep_center(all_predictors()) %\u0026gt;%\rstep_scale(all_predictors()) %\u0026gt;%\rstep_log(sale_price, base = 10)\rA few additional things are added. First of all, step_other() is a great fallback step in case there is a category that appears in the test set but didn’t appear in the training set. Usually this would throw an error but Tidymodels will automatically create a category called ‘Other’ for those. Then there’s step_dummy() which converts our neighborhood and overall_qual columns to dummies. To see what the data looks like once it’s been processed:\njuice(prep(glm_rec)) %\u0026gt;%\rhead(5)\r#\u0026gt; # A tibble: 5 x 22\r#\u0026gt; longitude latitude lot_area year_sold sale_price neighborhood_Co~\r#\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r#\u0026gt; 1 0.899 1.07 2.48 1.69 5.33 -0.318\r#\u0026gt; 2 0.899 1.02 0.160 1.69 5.02 -0.318\r#\u0026gt; 3 0.913 0.999 0.465 1.69 5.24 -0.318\r#\u0026gt; 4 0.154 1.45 0.415 1.69 5.28 -0.318\r#\u0026gt; 5 0.155 1.44 -0.0298 1.69 5.29 -0.318\r#\u0026gt; # ... with 16 more variables: neighborhood_Old_Town \u0026lt;dbl\u0026gt;,\r#\u0026gt; # neighborhood_Edwards \u0026lt;dbl\u0026gt;, neighborhood_Somerset \u0026lt;dbl\u0026gt;,\r#\u0026gt; # neighborhood_Northridge_Heights \u0026lt;dbl\u0026gt;, neighborhood_Gilbert \u0026lt;dbl\u0026gt;,\r#\u0026gt; # neighborhood_Sawyer \u0026lt;dbl\u0026gt;, neighborhood_other \u0026lt;dbl\u0026gt;,\r#\u0026gt; # overall_qual_Poor \u0026lt;dbl\u0026gt;, overall_qual_Fair \u0026lt;dbl\u0026gt;,\r#\u0026gt; # overall_qual_Below_Average \u0026lt;dbl\u0026gt;, overall_qual_Average \u0026lt;dbl\u0026gt;,\r#\u0026gt; # overall_qual_Above_Average \u0026lt;dbl\u0026gt;, overall_qual_Good \u0026lt;dbl\u0026gt;,\r#\u0026gt; # overall_qual_Very_Good \u0026lt;dbl\u0026gt;, overall_qual_Excellent \u0026lt;dbl\u0026gt;,\r#\u0026gt; # overall_qual_Very_Excellent \u0026lt;dbl\u0026gt;\rNow let’s go to step 2, creating the model:\nglm_model \u0026lt;-\rlinear_reg(penalty = 0.001, mixture = 0.5) %\u0026gt;%\rset_engine(\u0026quot;glmnet\u0026quot;)\rStep 3 and step 4, which is putting together the workflow and fitting the data:\nglm_wf \u0026lt;-\rworkflow() %\u0026gt;%\radd_recipe(glm_rec) %\u0026gt;%\radd_model(glm_model)\rset.seed(123)\rglm_fit \u0026lt;-\rglm_wf %\u0026gt;%\rfit_resamples(resamples = ames_folds)\rglm_fit %\u0026gt;%\rcollect_metrics()\r#\u0026gt; # A tibble: 2 x 5\r#\u0026gt; .metric .estimator mean n std_err\r#\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt;\r#\u0026gt; 1 rmse standard 0.0970 10 0.00410\r#\u0026gt; 2 rsq standard 0.703 10 0.0231\rAnd finally predict. Then we’ll put together the metrics for the two models (and pretend the first one didn’t happen..) and see whether the glmnet or the tree performed best.\nset.seed(123)\rglm_last_fit \u0026lt;-\rglm_wf %\u0026gt;%\rlast_fit(split = ames_split)\rresults_glm \u0026lt;- glm_last_fit %\u0026gt;% collect_metrics()\rglm_last_fit %\u0026gt;%\rcollect_predictions() %\u0026gt;%\rggplot(aes(.pred, sale_price)) +\rgeom_abline(col = \u0026quot;green\u0026quot;, lty = 2) +\rgeom_point(alpha = .4, colour = \u0026quot;midnightblue\u0026quot;) +\rannotate(\u0026quot;text\u0026quot;, x = Inf, y = Inf, hjust = 6.5, vjust = 2.5, label = paste(\u0026quot;RMSE: \u0026quot;, round(results_log10$.estimate[1], 4))) +\rlabs(title = \u0026quot;Linear regression model\u0026quot;,\rsubtitle = \u0026quot;Variety of steps in recipe, glmnet engine\u0026quot;) +\rscale_x_continuous(labels = scales::dollar_format()) +\rscale_y_continuous(labels = scales::dollar_format())\r\rFinal\rNow let’s simply combine the prediction data for the two models and plot them side-by-side so we can see which one has performed best:\ntest_results \u0026lt;- rf_log10_last_fit %\u0026gt;%\rcollect_predictions() %\u0026gt;%\rrename(\u0026quot;rf\u0026quot; = .pred) %\u0026gt;%\rbind_cols(\rglm_last_fit %\u0026gt;%\rcollect_predictions() %\u0026gt;%\rrename(\u0026quot;glmnet\u0026quot; = .pred) %\u0026gt;%\rselect(\u0026quot;glmnet\u0026quot;)\r) %\u0026gt;%\rselect(-id, -.row)\rtest_results %\u0026gt;%\rgather(model, prediction, -sale_price) %\u0026gt;%\rggplot(aes(prediction, sale_price)) +\rgeom_abline(col = \u0026quot;green\u0026quot;, lty = 2) +\rgeom_point(col = \u0026quot;midnightblue\u0026quot;, alpha = .7) +\rfacet_wrap(~model) +\rcoord_fixed()\rWhen putting them side-by-side it looks like the tree model performed just slightly better. That said, they both did alright. In conclusion, Tidymodels has made the process that caret helped introduce even better. It’s very simple to fit a model, update a few steps, update the workflow, fit another model. Whilst in this article I used very simple models I can see it come to very good use when I’m trying to tune hyper-parameters with things like XGBoost!\n\r"
            }
        
    ,
        
            {
                "ref": "https://duncip.netlify.app/2020/06/08/exploring-tidymodels-with-regression-models/",
                "title": "Exploring Tidymodels with Regression Models",
                "section": "post",
                "date" : "2020.06.08",
                "body": "Title Contents "
            }
        
    
]