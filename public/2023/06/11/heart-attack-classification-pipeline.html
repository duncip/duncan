<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />

  <title>Using scikit&#39;s pipeline for a Heart Attack classification model</title>
  <meta name="author" content="Duncan Pastoors">
  <meta name="description" content="Using a mix of R and Python for EDA and modelling">


<script>
  (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-KK6SXDK');
</script>
  



<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="alternate" type="application/rss+xml" href="https://duncanpastoors.com/index.xml" title="Duncan Pastoors">


<link rel="stylesheet" href="https://duncanpastoors.com/fontawesome/css/fontawesome.css" />
<link rel="stylesheet" href="https://duncanpastoors.com/fontawesome/css/brands.css" />
<link rel="stylesheet" href="https://duncanpastoors.com/fontawesome/css/solid.css" />

<link rel="stylesheet" href="https://duncanpastoors.com/css/dp-styles.css" />
<link rel="stylesheet" href="https://duncanpastoors.com/css/main.css" />
<link rel="stylesheet" href="https://duncanpastoors.com/css/zenburn.css" id="theme-stylesheet">

<script src="https://duncanpastoors.com/js/bundle.js"></script>
<script src="https://duncanpastoors.com/js/instantpage.js" type="module" defer></script>
<script src="https://duncanpastoors.com/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<meta name="generator" content="Hugo 0.72.0" />
  </head>
  <body>
    
  


<noscript>
  <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KK6SXDK"
height="0" width="0" style="display:none;visibility:hidden"></iframe>
</noscript>



  <header>
    <nav class="navbar">
  <div class="nav">
    
      <a href="https://duncanpastoors.com/" class="nav-logo">
      <img src="https://duncanpastoors.com/images/dp_logo.png"
           width="50"
           height="50"
           alt="Logo">
      </a>
    

    <ul class="nav-links">
      
        
          <li><a href="/tags" name="Tags"><i class="fas fa-tag fa-lg"></i></a></li>
        
      
    </ul>
  </div>
</nav>

    <div class="intro-header">
      <div class="container">
        <div class="post-heading">
          
            
              <h1>Using scikit&#39;s pipeline for a Heart Attack classification model</h1>
            
          
          
            <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>&nbsp;Jun 11, 2023
  
    &nbsp;&nbsp;&nbsp;<i class="fa fa-folder-open"></i>&nbsp;
    
      <a href="https://duncanpastoors.com//categories/modeling/">modeling</a>&nbsp;
    
      <a href="https://duncanpastoors.com//categories/classification/">classification</a>&nbsp;
    
      <a href="https://duncanpastoors.com//categories/python/">python</a>&nbsp;
    
      <a href="https://duncanpastoors.com//categories/r/">r</a>&nbsp;
    
  
</span>

          
        </div>
      </div>
    </div>
  </header>


    

  <div class="container" role="main">
    <article class="article" class="blog-post">
      
    </p>
<p>I’ve recently been going through some <a href="https://www.dataschool.io/">dataschool.io</a> scikit-learn videos and one of the tips that stood out to me was about how you can use a <a href="https://www.youtube.com/watch?v=gd-TZut-oto">simple approach</a> for many different machine learning problems. I liked the usage of the <code>Pipeline</code> function in particular because it reminded me of R functionality and so wanted to give it a try. I found one the most popular classification datasets on Kaggle, the <a href="https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset?datasetId=216167&amp;searchQuery=kn">heart attack dataset</a> and here we are. I don’t get to use R very much any more so I still want to do some EDA / plotting in R and then do the modelling using scikit-learn. Let’s have a look at the dataset:</p>
<pre><code>#&gt; # A tibble: 5 x 14
#&gt;     age   sex    cp trestbps  chol   fbs restecg thalach exang oldpeak slope
#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
#&gt; 1    52     1     0      125   212     0       1     168     0     1       2
#&gt; 2    53     1     0      140   203     1       0     155     1     3.1     0
#&gt; 3    70     1     0      145   174     0       1     125     1     2.6     0
#&gt; 4    61     1     0      148   203     0       1     161     0     0       2
#&gt; 5    62     0     0      138   294     1       1     106     0     1.9     1
#&gt; # ... with 3 more variables: ca &lt;dbl&gt;, thal &lt;dbl&gt;, target &lt;dbl&gt;</code></pre>
<p>The columns are as follows:</p>
<blockquote>
<ul>
<li>Age (age in years)</li>
<li>Sex (1 = male; 0 = female)</li>
<li>CP (chest pain type)</li>
<li>TRESTBPS (resting blood pressure (in mm Hg on admission to the hospital))</li>
<li>CHOL (serum cholestoral in mg/dl)</li>
<li>FPS (fasting blood sugar &gt; 120 mg/dl) (1 = true; 0 = false)</li>
<li>RESTECH (resting electrocardiographic results)</li>
<li>THALACH (maximum heart rate achieved)</li>
<li>EXANG (exercise induced angina (1 = yes; 0 = no))</li>
<li>OLDPEAK (ST depression induced by exercise relative to rest)</li>
<li>SLOPE (the slope of the peak exercise ST segment)</li>
<li>CA (number of major vessels (0-3) colored by flourosopy)</li>
<li>THAL (3 = normal; 6 = fixed defect; 7 = reversable defect)</li>
<li>TARGET (1 or 0)</li>
</ul>
</blockquote>
<p>Let’s have a look and see if there are null values and if anything weird jumps out with the distributions:</p>
<pre><code>#&gt;       age             sex               cp            trestbps    
#&gt;  Min.   :29.00   Min.   :0.0000   Min.   :0.0000   Min.   : 94.0  
#&gt;  1st Qu.:48.00   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:120.0  
#&gt;  Median :56.00   Median :1.0000   Median :1.0000   Median :130.0  
#&gt;  Mean   :54.43   Mean   :0.6956   Mean   :0.9424   Mean   :131.6  
#&gt;  3rd Qu.:61.00   3rd Qu.:1.0000   3rd Qu.:2.0000   3rd Qu.:140.0  
#&gt;  Max.   :77.00   Max.   :1.0000   Max.   :3.0000   Max.   :200.0  
#&gt;       chol          fbs            restecg          thalach     
#&gt;  Min.   :126   Min.   :0.0000   Min.   :0.0000   Min.   : 71.0  
#&gt;  1st Qu.:211   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:132.0  
#&gt;  Median :240   Median :0.0000   Median :1.0000   Median :152.0  
#&gt;  Mean   :246   Mean   :0.1493   Mean   :0.5298   Mean   :149.1  
#&gt;  3rd Qu.:275   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:166.0  
#&gt;  Max.   :564   Max.   :1.0000   Max.   :2.0000   Max.   :202.0  
#&gt;      exang           oldpeak          slope             ca        
#&gt;  Min.   :0.0000   Min.   :0.000   Min.   :0.000   Min.   :0.0000  
#&gt;  1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:1.000   1st Qu.:0.0000  
#&gt;  Median :0.0000   Median :0.800   Median :1.000   Median :0.0000  
#&gt;  Mean   :0.3366   Mean   :1.072   Mean   :1.385   Mean   :0.7541  
#&gt;  3rd Qu.:1.0000   3rd Qu.:1.800   3rd Qu.:2.000   3rd Qu.:1.0000  
#&gt;  Max.   :1.0000   Max.   :6.200   Max.   :2.000   Max.   :4.0000  
#&gt;       thal           target      
#&gt;  Min.   :0.000   Min.   :0.0000  
#&gt;  1st Qu.:2.000   1st Qu.:0.0000  
#&gt;  Median :2.000   Median :1.0000  
#&gt;  Mean   :2.324   Mean   :0.5132  
#&gt;  3rd Qu.:3.000   3rd Qu.:1.0000  
#&gt;  Max.   :3.000   Max.   :1.0000</code></pre>
<p>Thankfully with it being a Kaggle dataset, a lot of the cleaning etc. has already been done and there are no null values here. Additionally, the dataset has been updated so variables like sex and chest pain type are already numerically encoded which means we don’t have to do that. We’ll use a boxplot to see if there are outliers that jump out:</p>
<pre class="r"><code>heart_df %&gt;%
  select(age, trestbps, chol, thalach) %&gt;%
  reshape2::melt() %&gt;%
  ggplot() +
  geom_boxplot(aes(x = variable, y = value, colour = variable)) +
  facet_wrap(~variable, scales=&quot;free&quot;) +
  labs(title = &quot;Spotting outliers&quot;,
       x = NULL,
       y = NULL) +
  theme(legend.position = &quot;none&quot;)
#&gt; No id variables; using all as measure variables</code></pre>
<p><img src="/post/2023-06-11-heartattacks-scikitlearn-classification_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>We can see that <code>age</code> is fine but <code>trestbps</code>, <code>chol</code>, and <code>thalach</code> all have outliers that we need to be aware of. Not going to do anything to them yet but will see if changing those makes a difference to the model evaluation. Lastly I’ll check if there are obvious correlations between variables and if there’s a class imbalance for the target variable, and then on to the model!</p>
<pre class="r"><code>corrplot::corrplot(cor(heart_df, method=&quot;spearman&quot;))</code></pre>
<p><img src="/post/2023-06-11-heartattacks-scikitlearn-classification_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>I also want to double-check if there’s a class imbalance in case we need to do some under/over-sampling</p>
<p><img src="/post/2023-06-11-heartattacks-scikitlearn-classification_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>All good here :)</p>
<div id="modelling" class="section level1">
<h1>Modelling</h1>
<p>Preferably we would’ve tried things like one hot encoding, filling null values etc. all in a single pipeline but because the dataset we’re working with is already great, we don’t need to do that. So instead, we’ll just do the scaling in the pipeline so we can easily switch between 2 models. For this, I’ll use Python</p>
<pre class="python"><code>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.pipeline import make_pipeline, Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score, classification_report, roc_curve, roc_auc_score
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier


heart_df_p = r.heart_df
heart_df_p.head()
#&gt;     age  sex   cp  trestbps   chol  ...  oldpeak  slope   ca  thal  target
#&gt; 0  52.0  1.0  0.0     125.0  212.0  ...      1.0    2.0  2.0   3.0     0.0
#&gt; 1  53.0  1.0  0.0     140.0  203.0  ...      3.1    0.0  0.0   3.0     0.0
#&gt; 2  70.0  1.0  0.0     145.0  174.0  ...      2.6    0.0  0.0   3.0     0.0
#&gt; 3  61.0  1.0  0.0     148.0  203.0  ...      0.0    2.0  1.0   3.0     0.0
#&gt; 4  62.0  0.0  0.0     138.0  294.0  ...      1.9    1.0  3.0   2.0     0.0
#&gt; 
#&gt; [5 rows x 14 columns]</code></pre>
<p>And then create a training/test split:</p>
<pre class="python"><code>X = heart_df_p.drop(&#39;target&#39;, axis=1)
y = heart_df_p[&#39;target&#39;]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)</code></pre>
<p>Now we can start our Pipeline. Again, even though there aren’t many steps needed for this data I still think the pipeline allows for great readability</p>
<pre class="python"><code>pipeline_lr = Pipeline([(&#39;scl&#39;, StandardScaler()),
                            (&#39;clf&#39;, LogisticRegression(random_state=12))])
                            
pipeline_knn = Pipeline([(&#39;scl&#39;, StandardScaler()),
                            (&#39;clf&#39;, KNeighborsClassifier())])
                            
print(&#39;LR: &#39; + str(cross_val_score(pipeline_lr, X_train, y_train, cv=5, scoring=&#39;accuracy&#39;).mean()))
#&gt; LR: 0.8409673659673661
print(&#39;KNN: &#39; + str(cross_val_score(pipeline_knn, X_train, y_train, cv=5, scoring=&#39;accuracy&#39;).mean()))                            
#&gt; KNN: 0.8479700854700856</code></pre>
<p>Obviously we haven’t done anything yet in terms of parameters but this is already quite a good score. Let’s try to do some parameter tuning.</p>
</div>
<div id="gridsearchcv-parameters" class="section level1">
<h1>GridSearchCV parameters</h1>
<p>We’re only using two models so the parameter tuning shouldn’t be difficult. For the <code>LogisticRegression</code> model, I want to try different values for:</p>
<ul>
<li><code>penalty</code> - <code>l2</code> is the default, changes the norm of the penalty</li>
<li><code>C</code> - inverse of regularization strength</li>
<li><code>solver</code> - algorithm to use (the one used above is <code>lbfgs</code>). The docs say <code>liblinear</code> is good for small datasets so I want to try that</li>
</ul>
<p>For KNN I’ll only try different values for <code>n_neighbors</code>.</p>
<pre class="python"><code>grid_params_lr = [{&#39;clf__penalty&#39;: [&#39;l1&#39;,&#39;l2&#39;],
                  &#39;clf__C&#39;: [1.0, 0.5, 0.1],
                  &#39;clf__solver&#39;: [&#39;liblinear&#39;],
                  &#39;clf__random_state&#39;: [13]}]
                  
grid_params_knn = [{&#39;clf__n_neighbors&#39;: np.arange(1, 31)}]                   
                  
gs_lr = GridSearchCV(estimator = pipeline_lr,
                    param_grid = grid_params_lr,
                    scoring=&#39;accuracy&#39;,
                    cv = 10)
                    
gs_knn = GridSearchCV(estimator = pipeline_knn,
                    param_grid = grid_params_knn,
                    scoring=&#39;accuracy&#39;,
                    cv = 10)                    </code></pre>
<pre class="python"><code>grids = [gs_lr, gs_knn]
grid_dict = {0: &#39;Logistic Regression&#39;, 1: &#39;KNN&#39;}


for idx, gridSearch in enumerate(grids):
  print(&#39;Estimator: %s&#39; % grid_dict[idx])
  gridSearch.fit(X_train, y_train)
  print(&#39;Best params: %s&#39; % gridSearch.best_params_)
  print(&#39;Best training accuracy: %s&#39; % gridSearch.best_score_)
  
  y_preds = gridSearch.predict(X_test)
  print(&#39;Test set accuracy: %s&#39; % accuracy_score(y_test, y_preds))
#&gt; Estimator: Logistic Regression
#&gt; GridSearchCV(cv=10,
#&gt;              estimator=Pipeline(steps=[(&#39;scl&#39;, StandardScaler()),
#&gt;                                        (&#39;clf&#39;,
#&gt;                                         LogisticRegression(random_state=12))]),
#&gt;              param_grid=[{&#39;clf__C&#39;: [1.0, 0.5, 0.1],
#&gt;                           &#39;clf__penalty&#39;: [&#39;l1&#39;, &#39;l2&#39;],
#&gt;                           &#39;clf__random_state&#39;: [13],
#&gt;                           &#39;clf__solver&#39;: [&#39;liblinear&#39;]}],
#&gt;              scoring=&#39;accuracy&#39;)
#&gt; Best params: {&#39;clf__C&#39;: 1.0, &#39;clf__penalty&#39;: &#39;l1&#39;, &#39;clf__random_state&#39;: 13, &#39;clf__solver&#39;: &#39;liblinear&#39;}
#&gt; Best training accuracy: 0.8464593114241001
#&gt; Test set accuracy: 0.8441558441558441
#&gt; Estimator: KNN
#&gt; GridSearchCV(cv=10,
#&gt;              estimator=Pipeline(steps=[(&#39;scl&#39;, StandardScaler()),
#&gt;                                        (&#39;clf&#39;, KNeighborsClassifier())]),
#&gt;              param_grid=[{&#39;clf__n_neighbors&#39;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
#&gt;        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])}],
#&gt;              scoring=&#39;accuracy&#39;)
#&gt; Best params: {&#39;clf__n_neighbors&#39;: 1}
#&gt; Best training accuracy: 0.9763693270735525
#&gt; Test set accuracy: 1.0</code></pre>
<p>Obviously there is some overfitting happening here as there is no way our model should be getting 100% accuracy. For the sake of learning, I want to see what’s going on with the KNN model:</p>
</div>
<div id="troubleshoot" class="section level1">
<h1>Troubleshoot</h1>
<pre class="python"><code>param_grid = {&#39;n_neighbors&#39;: np.arange(5,30)}
knn = KNeighborsClassifier()
knn_cv = GridSearchCV(knn, param_grid=param_grid, cv=5)
knn_cv.fit(X_train, y_train)
#&gt; GridSearchCV(cv=5, estimator=KNeighborsClassifier(),
#&gt;              param_grid={&#39;n_neighbors&#39;: array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,
#&gt;        22, 23, 24, 25, 26, 27, 28, 29])})
print(&#39;Best Score: %s&#39; % knn_cv.best_score_)
#&gt; Best Score: 0.7378302253302252
print(&#39;Best Parameters: %s&#39; % knn_cv.best_params_)
#&gt; Best Parameters: {&#39;n_neighbors&#39;: 8}</code></pre>
<pre><code>#&gt; KNeighborsClassifier(n_neighbors=1)
#&gt; KNeighborsClassifier(n_neighbors=2)
#&gt; KNeighborsClassifier(n_neighbors=3)
#&gt; KNeighborsClassifier(n_neighbors=4)
#&gt; KNeighborsClassifier()
#&gt; KNeighborsClassifier(n_neighbors=6)
#&gt; KNeighborsClassifier(n_neighbors=7)
#&gt; KNeighborsClassifier(n_neighbors=8)
#&gt; KNeighborsClassifier(n_neighbors=9)
#&gt; KNeighborsClassifier(n_neighbors=10)
#&gt; KNeighborsClassifier(n_neighbors=11)
#&gt; KNeighborsClassifier(n_neighbors=12)
#&gt; KNeighborsClassifier(n_neighbors=13)
#&gt; KNeighborsClassifier(n_neighbors=14)
#&gt; KNeighborsClassifier(n_neighbors=15)
#&gt; KNeighborsClassifier(n_neighbors=16)
#&gt; KNeighborsClassifier(n_neighbors=17)
#&gt; KNeighborsClassifier(n_neighbors=18)
#&gt; KNeighborsClassifier(n_neighbors=19)
#&gt; KNeighborsClassifier(n_neighbors=20)
#&gt; KNeighborsClassifier(n_neighbors=21)
#&gt; KNeighborsClassifier(n_neighbors=22)
#&gt; KNeighborsClassifier(n_neighbors=23)
#&gt; KNeighborsClassifier(n_neighbors=24)
#&gt; KNeighborsClassifier(n_neighbors=25)
#&gt; KNeighborsClassifier(n_neighbors=26)
#&gt; KNeighborsClassifier(n_neighbors=27)
#&gt; KNeighborsClassifier(n_neighbors=28)
#&gt; KNeighborsClassifier(n_neighbors=29)</code></pre>
<pre class="r"><code>py$knn_df %&gt;%
  pivot_longer(cols = c(&quot;test_acc&quot;, &quot;train_acc&quot;), names_to = &quot;dataset&quot;) %&gt;%
  ggplot(aes(x = K, y = value, col = dataset)) +
  geom_line() +
  geom_point() +
  ylim(c(0, 1))</code></pre>
<p><img src="/post/2023-06-11-heartattacks-scikitlearn-classification_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
</div>
<div id="picking-a-model-and-evaluating" class="section level1">
<h1>Picking a model and evaluating</h1>
<p>It looks like, when we disregard the fact that lower k neighbors lead to overfitting here, the optimal k number is 12 for the test set. I just want to compare the accuracy and precision of this model compared to our best logreg model and then use a confusion matrix to see how good our best model actually is</p>
<pre><code>#&gt; LR accuracy: 0.839539627039627
#&gt; KNN accuracy: 0.8521367521367521</code></pre>
<pre><code>#&gt; LR recall: 0.8984144144144144
#&gt; KNN recall: 0.8342702702702702</code></pre>
<p>Because we want to make sure that those who are likely to have a heart attack are correctly identified, we’ll go with the Logistic Regression model which has a higher recall rate</p>
<div id="evaluating" class="section level2">
<h2>Evaluating</h2>
<pre class="python"><code>pipeline_lr.fit(X_train, y_train)
#&gt; Pipeline(steps=[(&#39;scl&#39;, StandardScaler()),
#&gt;                 (&#39;clf&#39;,
#&gt;                  LogisticRegression(penalty=&#39;l1&#39;, random_state=12,
#&gt;                                     solver=&#39;liblinear&#39;))])
y_pred_class = pipeline_lr.predict(X_test)</code></pre>
<pre class="python"><code>print(&#39;Accuracy score of our model: %s&#39; % accuracy_score(y_test, y_pred_class))
#&gt; Accuracy score of our model: 0.8441558441558441
print(&#39;Null accuracy score: %s&#39; % max(y_test.mean(), 1- y_test.mean()))
#&gt; Null accuracy score: 0.5064935064935066</code></pre>
<p>Obviously the accuracy score is still not great when you consider the subject. To get a clearer idea of where it’s going wrong, I’ll use a confusion matrix</p>
<pre class="python"><code>cnf_matrix = confusion_matrix(y_test, y_pred_class)
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, fmt=&#39;g&#39;)
#&gt; &lt;AxesSubplot:&gt;
plt.ylabel(&#39;Actuals&#39;)
#&gt; Text(116.44444444444443, 0.5, &#39;Actuals&#39;)
plt.xlabel(&#39;Predicted&#39;)
#&gt; Text(0.5, 51.44444444444443, &#39;Predicted&#39;)
plt.show()</code></pre>
<p><img src="/post/2023-06-11-heartattacks-scikitlearn-classification_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Can see that just slightly it’s better at predicting positives rather than negatives. Not entirely sure what we could alter to make this even better, but for now I am happy with this. Lastly I want to use a classification report and an ROC curve, just to round it off.</p>
<pre class="python"><code>print(classification_report(y_test, y_pred_class))
#&gt;               precision    recall  f1-score   support
#&gt; 
#&gt;          0.0       0.92      0.76      0.83       156
#&gt;          1.0       0.79      0.93      0.85       152
#&gt; 
#&gt;     accuracy                           0.84       308
#&gt;    macro avg       0.85      0.85      0.84       308
#&gt; weighted avg       0.85      0.84      0.84       308</code></pre>
<p>This doesn’t tell us anything the confusion matrix didn’t already tell us really. We can see it has a high recall rate which is good for this dataset.</p>
<pre class="python"><code>y_pred_proba = pipeline_lr.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)

plt.plot([0,1], [0,1], &#39;k--&#39;)
#&gt; [&lt;matplotlib.lines.Line2D object at 0x000000003B2F2DF0&gt;]
plt.plot(fpr, tpr, label=&#39;knn&#39;)
#&gt; [&lt;matplotlib.lines.Line2D object at 0x000000003ADD2280&gt;]
plt.xlabel(&#39;fpr&#39;)
#&gt; Text(0.5, 0, &#39;fpr&#39;)
plt.ylabel(&#39;tpr&#39;)
#&gt; Text(0, 0.5, &#39;tpr&#39;)
plt.title(&#39;KNNeighbors = 12, ROC Curve&#39;)
#&gt; Text(0.5, 1.0, &#39;KNNeighbors = 12, ROC Curve&#39;)
plt.show()</code></pre>
<p><img src="/post/2023-06-11-heartattacks-scikitlearn-classification_files/figure-html/unnamed-chunk-6-3.png" width="672" /></p>
<pre class="python"><code>roc_auc_score(y_test, y_pred_proba)
#&gt; 0.9123228744939271</code></pre>
<p>And that’s it! I like the <code>Pipeline</code> function because it reminds me more of R syntax, where you’re constantly chaining things and everything is very readable. In this example I didn’t get to put it to much use due to the data already being very clean. I also verged slightly sideways due to the overfitting example but I’m looking forward to using the Pipe more in the future.</p>
</div>
</div>


      
        <div class="blog-tags">
          
            <a href="https://duncanpastoors.com//tags/modeling/">modeling</a>&nbsp;
          
            <a href="https://duncanpastoors.com//tags/python/">python</a>&nbsp;
          
            <a href="https://duncanpastoors.com//tags/r/">r</a>&nbsp;
          
        </div>
      
    </article>
    
  </div>

    <footer>
  <div class="container">
      <p class="credits theme-by">
        Powered By <a href="https://gohugo.io">Hugo</a>&nbsp;Theme <a href="https://github.com/matsuyoshi30/harbor">Harbor</a>
      </p>
    <div class="container text-center social-icons">
      <a href="https://github.com/duncip"><i class="fab fa-github-square"></i></a>
      <a href="https://twitter.com/duncip"><i class="fas fa-hashtag"></i></a>
      <a href="mailto:duncanpastoors@gmail.com"><i class="fas fa-reply"></i></a>
    </div>
  </div>
</footer>

  </body>
</html>
